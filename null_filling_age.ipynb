{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import ensemble\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed for reproducibility\n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and clean data\n",
    "def clean_df(df, test=False):\n",
    "    \n",
    "    # Drop PassengerId and Name\n",
    "    df.drop('PassengerId', axis='columns', inplace=True)\n",
    "    df.drop('Name', axis='columns', inplace=True)\n",
    "\n",
    "    # Cabin dictionary, char to int\n",
    "    cabin_dict = {\n",
    "    'A':0,\n",
    "    'B':1,\n",
    "    'C':2,\n",
    "    'D':3,\n",
    "    'E':4,\n",
    "    'F':5,\n",
    "    'G':6,\n",
    "    'T':7\n",
    "    }\n",
    "\n",
    "# Define list for new column in dataframe\n",
    "    chars_ids = []\n",
    "    numbers = []\n",
    "    # Change cabin column to cabin letter column and cabin number column\n",
    "    # Iterate by rows\n",
    "    for c_i, cabin in enumerate(df['Cabin']):\n",
    "        # Change only value with str datatype\n",
    "        if not isinstance(cabin,str):\n",
    "            continue\n",
    "        # Iterate by row value\n",
    "        for n_i ,char in enumerate(cabin):\n",
    "            # Start iterating from last to first char\n",
    "            index = -1 - n_i\n",
    "            # If given char in cabin dictionary\n",
    "            if cabin[index] in cabin_dict.keys():\n",
    "                # Append cabin id\n",
    "                chars_ids.append(int(cabin_dict[cabin[index]]))\n",
    "                # Cabin number\n",
    "                cabin_number = str(df['Cabin'][c_i][index+1:])\n",
    "                # If cabin number == cabin letter put 0\n",
    "                if cabin_number in cabin_dict.keys(): cabin_number = 0\n",
    "                # Append cabin number\n",
    "                numbers.append(int(cabin_number))\n",
    "                break\n",
    "\n",
    "    # Create new columns\n",
    "    df['Cabin_char_id'] = chars_ids\n",
    "    df['Cabin_number'] = numbers\n",
    "    # Delete old Cabin column\n",
    "    df.drop('Cabin', axis='columns', inplace=True)\n",
    "\n",
    "    # Change ticket value just to numbers\n",
    "    # Iterate by rows\n",
    "    for t_i, ticket in enumerate(df['Ticket']):\n",
    "        # If ticket value == LINE change to 0\n",
    "        if ticket == 'LINE':\n",
    "            df.loc[t_i, 'Ticket'] = 0\n",
    "        # Iterate by row value\n",
    "        for c_i ,char in enumerate(ticket):\n",
    "            # Start iterating from last to first char\n",
    "            index = -1 - c_i\n",
    "            # If whitespace found \n",
    "            if ticket[index] == ' ':\n",
    "                # Change value to numbers after whitespace\n",
    "                df.loc[t_i, 'Ticket'] = df['Ticket'][t_i][index+1:]   \n",
    "                break\n",
    "        continue\n",
    "\n",
    "    # Reset dataframe indexing\n",
    "    df.reset_index()\n",
    "\n",
    "    # Create column for each embarked\n",
    "    df['Embarked_C'] = [1 if embarked == 'C' else 0 for embarked in df['Embarked']]\n",
    "    df['Embarked_Q'] = [1 if embarked == 'Q' else 0 for embarked in df['Embarked']]\n",
    "    df['Embarked_S'] = [1 if embarked == 'S' else 0 for embarked in df['Embarked']]\n",
    "\n",
    "    # delete old embarked column\n",
    "    df.drop('Embarked', axis='columns', inplace=True)\n",
    "\n",
    "    # Sex dictionary, str to int\n",
    "    sex_dict = {\n",
    "        'male':0,\n",
    "        'female':1\n",
    "    }\n",
    "\n",
    "    # Replace values in dataframe with dictionary\n",
    "    df.replace({'Sex':sex_dict}, inplace=True)\n",
    "\n",
    "    # Fill na values with mean\n",
    "    df.fillna(\n",
    "                {\n",
    "                'Fare': df['Fare'].mean(),\n",
    "                },\n",
    "                inplace=True\n",
    "                ) \n",
    "    \n",
    "    # If training data save temporary column\n",
    "    if not test:\n",
    "        df_y = df['Age']\n",
    "        df_y= (df_y).astype(float)\n",
    "        # drop Age from dataframe\n",
    "        df.drop('Age', axis='columns', inplace=True)\n",
    "    \n",
    "    # drop rows with empty Ticket value\n",
    "    df = df[df.Ticket != '']\n",
    "    \n",
    "    # Change Ticket datatype\n",
    "    df['Ticket'] = (df['Ticket']).astype(float)\n",
    "\n",
    "    # If training join Age column\n",
    "    if not test:\n",
    "        df = df.join(df_y)\n",
    "        max_age = df['Age'].max()\n",
    "\n",
    "    # Change dataframe values range from 0 to 1\n",
    "    df=(df-df.min())/(df.max()-df.min())\n",
    "\n",
    "    # If training return dataframe and max Age value\n",
    "    if not test:\n",
    "        return df, max_age\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 331 entries, 0 to 330\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Pclass         331 non-null    float64\n",
      " 1   Sex            331 non-null    float64\n",
      " 2   SibSp          331 non-null    float64\n",
      " 3   Parch          331 non-null    float64\n",
      " 4   Ticket         331 non-null    float64\n",
      " 5   Fare           331 non-null    float64\n",
      " 6   Cabin_char_id  331 non-null    float64\n",
      " 7   Cabin_number   331 non-null    float64\n",
      " 8   Embarked_C     331 non-null    float64\n",
      " 9   Embarked_Q     331 non-null    float64\n",
      " 10  Embarked_S     331 non-null    float64\n",
      " 11  Age            331 non-null    float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 31.2 KB\n",
      "None\n",
      "331\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "DATA_PATH = 'data'\n",
    "train_data_path = os.path.join(DATA_PATH,'test.csv')\n",
    "train_df = pd.read_csv(train_data_path, sep=',')\n",
    "\n",
    "# load predicted features\n",
    "cabin_chars_path = 'filled_null_cabin_chars_test.csv'\n",
    "cabin_chars = pd.read_csv(cabin_chars_path, sep=',')\n",
    "cabin_chars['value'] = (cabin_chars['value']).astype(str)\n",
    "cabin_chars.set_index('PassengerId',inplace=True)\n",
    "\n",
    "cabin_numbers_path = 'filled_null_cabin_numbers_test.csv'\n",
    "cabin_numbers = pd.read_csv(cabin_numbers_path, sep=',')\n",
    "cabin_numbers['value'] = (cabin_numbers['value']).astype(str)\n",
    "cabin_numbers.set_index('PassengerId',inplace=True)\n",
    "\n",
    "#fill null values\n",
    "train_df.loc[cabin_chars.index, 'Cabin'] = cabin_chars['value'] + cabin_numbers['value']\n",
    "\n",
    "# preprocess data\n",
    "test_df = train_df[train_df.isnull().any(axis=1)]\n",
    "test_df.reset_index(inplace=True)\n",
    "null_indexes = test_df['index']\n",
    "test_df.drop('index', axis='columns', inplace=True)\n",
    "test_df.drop('Age', axis='columns', inplace=True)\n",
    "test_df = clean_df(test_df, test=True)\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "train_df.reset_index(inplace=True)\n",
    "train_df.drop('index', axis='columns', inplace=True)\n",
    "train_df, df_max_age = clean_df(train_df)\n",
    "\n",
    "print(train_df.info())\n",
    "\n",
    "# change df to np\n",
    "train_set = train_df.to_numpy()\n",
    "test_set = test_df.to_numpy()\n",
    "\n",
    "#split data\n",
    "print(len(train_set))\n",
    "train_set, val_set = torch.utils.data.random_split(train_set, [280, 51])\n",
    "\n",
    "# change np to array | to avoid slice errors\n",
    "train_set = np.array(train_set)\n",
    "val_set = np.array(val_set)\n",
    "X_train,y_train = train_set[:,:-1],train_set[:,-1]\n",
    "X_val,y_val = val_set[:,:-1],val_set[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15475087,  0.39903485,  0.36887231,  0.34963474])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set params\n",
    "params = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"loss\": \"squared_error\",\n",
    "}\n",
    "\n",
    "# create model\n",
    "reg = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "# train model\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# score model\n",
    "reg.score(X_val, y_val)\n",
    "\n",
    "# cross validation\n",
    "scores = cross_val_score(reg, X_train, y_train, cv = 4)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'PassengerId': 10, 'value': 13},\n",
       " {'PassengerId': 22, 'value': 35},\n",
       " {'PassengerId': 29, 'value': 21},\n",
       " {'PassengerId': 33, 'value': 8},\n",
       " {'PassengerId': 36, 'value': 13},\n",
       " {'PassengerId': 39, 'value': 24},\n",
       " {'PassengerId': 41, 'value': 31},\n",
       " {'PassengerId': 47, 'value': 21},\n",
       " {'PassengerId': 54, 'value': 18},\n",
       " {'PassengerId': 58, 'value': 8},\n",
       " {'PassengerId': 65, 'value': 22},\n",
       " {'PassengerId': 76, 'value': 13},\n",
       " {'PassengerId': 83, 'value': 13},\n",
       " {'PassengerId': 84, 'value': 27},\n",
       " {'PassengerId': 85, 'value': 19},\n",
       " {'PassengerId': 88, 'value': 22},\n",
       " {'PassengerId': 91, 'value': 13},\n",
       " {'PassengerId': 93, 'value': 9},\n",
       " {'PassengerId': 102, 'value': 22},\n",
       " {'PassengerId': 107, 'value': 21},\n",
       " {'PassengerId': 108, 'value': 19},\n",
       " {'PassengerId': 111, 'value': 22},\n",
       " {'PassengerId': 116, 'value': 18},\n",
       " {'PassengerId': 121, 'value': 22},\n",
       " {'PassengerId': 124, 'value': 22},\n",
       " {'PassengerId': 127, 'value': 26},\n",
       " {'PassengerId': 132, 'value': 25},\n",
       " {'PassengerId': 133, 'value': 18},\n",
       " {'PassengerId': 146, 'value': 29},\n",
       " {'PassengerId': 148, 'value': 31},\n",
       " {'PassengerId': 151, 'value': 22},\n",
       " {'PassengerId': 152, 'value': 36},\n",
       " {'PassengerId': 160, 'value': 22},\n",
       " {'PassengerId': 163, 'value': 14},\n",
       " {'PassengerId': 168, 'value': 32},\n",
       " {'PassengerId': 170, 'value': 18},\n",
       " {'PassengerId': 173, 'value': 20},\n",
       " {'PassengerId': 183, 'value': 19},\n",
       " {'PassengerId': 188, 'value': 13},\n",
       " {'PassengerId': 191, 'value': 38},\n",
       " {'PassengerId': 199, 'value': 16},\n",
       " {'PassengerId': 200, 'value': 18},\n",
       " {'PassengerId': 205, 'value': 30},\n",
       " {'PassengerId': 211, 'value': 8},\n",
       " {'PassengerId': 216, 'value': 22},\n",
       " {'PassengerId': 219, 'value': 16},\n",
       " {'PassengerId': 225, 'value': 8},\n",
       " {'PassengerId': 227, 'value': 21},\n",
       " {'PassengerId': 233, 'value': 22},\n",
       " {'PassengerId': 243, 'value': 19},\n",
       " {'PassengerId': 244, 'value': 8},\n",
       " {'PassengerId': 249, 'value': 19},\n",
       " {'PassengerId': 255, 'value': 15},\n",
       " {'PassengerId': 256, 'value': 20},\n",
       " {'PassengerId': 265, 'value': 13},\n",
       " {'PassengerId': 266, 'value': 44},\n",
       " {'PassengerId': 267, 'value': 15},\n",
       " {'PassengerId': 268, 'value': 16},\n",
       " {'PassengerId': 271, 'value': 22},\n",
       " {'PassengerId': 273, 'value': 24},\n",
       " {'PassengerId': 274, 'value': 20},\n",
       " {'PassengerId': 282, 'value': 22},\n",
       " {'PassengerId': 286, 'value': 7},\n",
       " {'PassengerId': 288, 'value': 20},\n",
       " {'PassengerId': 289, 'value': 20},\n",
       " {'PassengerId': 290, 'value': 28},\n",
       " {'PassengerId': 292, 'value': 20},\n",
       " {'PassengerId': 297, 'value': 21},\n",
       " {'PassengerId': 301, 'value': 21},\n",
       " {'PassengerId': 304, 'value': 21},\n",
       " {'PassengerId': 312, 'value': 19},\n",
       " {'PassengerId': 332, 'value': 20},\n",
       " {'PassengerId': 339, 'value': 20},\n",
       " {'PassengerId': 342, 'value': 36},\n",
       " {'PassengerId': 344, 'value': 9},\n",
       " {'PassengerId': 357, 'value': 20},\n",
       " {'PassengerId': 358, 'value': 22},\n",
       " {'PassengerId': 365, 'value': 27},\n",
       " {'PassengerId': 366, 'value': 19},\n",
       " {'PassengerId': 380, 'value': 22},\n",
       " {'PassengerId': 382, 'value': 11},\n",
       " {'PassengerId': 384, 'value': 25},\n",
       " {'PassengerId': 408, 'value': 22},\n",
       " {'PassengerId': 410, 'value': 22},\n",
       " {'PassengerId': 413, 'value': 19},\n",
       " {'PassengerId': 416, 'value': 13},\n",
       " {'PassengerId': 417, 'value': 15}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = reg.predict(test_set)\n",
    "filled_null_ages = []\n",
    "for index, value in zip(null_indexes,pred):\n",
    "    filled_null_ages.append({\n",
    "        'PassengerId':index,\n",
    "        'value':int(round(value * df_max_age,0))\n",
    "    })\n",
    "filled_null_ages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(filled_null_ages)\n",
    "output.to_csv('filled_null_ages_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
